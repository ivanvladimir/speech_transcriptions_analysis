{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf84cbd-d5d2-475b-9d71-bb005ed00243",
   "metadata": {},
   "source": [
    "# Evaluation of speech transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea37a7c-a8ca-44ee-9cb8-564ccf2962b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jiwer\n",
    "import Levenshtein\n",
    "from collections import Counter\n",
    "from rich.jupyter import print\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "## Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c8cdd-4011-4746-a7d5-831159039444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions to match id and transcription\n",
    "re_id_head=re.compile(r\"^(?P<id>[^ ]+) (?P<trans>.*)\") # id at the start\n",
    "re_id_tail=re.compile(r\"(?P<trans>.*) (?P<id>[^ ]+)$\") # id at the final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fd7d9-0c49-4ed2-a050-c4044b3b5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the files and directories\n",
    "\n",
    "# Configure this\n",
    "REF_FILE=\"../data/test/CIEMPIESS_TEST.trans\"\n",
    "HYP_DIR=\"../data/output/exp_november2022\"\n",
    "\n",
    "# ---\n",
    "HYP_FILES={file:os.path.join(HYP_DIR,file) for file in os.listdir(HYP_DIR)}\n",
    "print(f\"[green bold]Files to analyse[/] in dir [{HYP_DIR}]:\\n \",\"\\n  \".join([file for file,_ in HYP_FILES.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf3530-1c15-47bc-a05f-51e8a6c835c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels to filenames (inspect files from previous output)\n",
    "\n",
    "# Configure this\n",
    "labels=[\"Go.\",\"QN\",\"W2V\",\"W tn.\",\"W bs.\", \"W sm.\", \"W med.\", \"W lg.\", \"QN FT\",\"W2V FT\"] # We will follow this order\n",
    "label2name={\n",
    "  \"W med.\":\"whisper_medium_ciempiess_test.trans\",\n",
    "  \"W sm.\":\"whisper_small_ciempiess_test.trans\",\n",
    "  \"W tn.\":\"whisper_tiny_ciempiess_test.trans\",\n",
    "  \"Go.\":\"google_ciempiess_test.trans\",\n",
    "  \"W2V FT\":\"wav2vec_carlos_ciempiess_test.trans\",\n",
    "  \"W lg.\":\"whisper_large_ciempiess_test.trans\",\n",
    "  \"W2V\":\"wav2vec_jonatasgrosman_ciempiess_test.trans\",\n",
    "  \"QN FT\":\"nemo_carlos_ciempiess_test.trans\",\n",
    "  \"QN\":\"nemo_nvidia_ciempiess_test.trans\",\n",
    "  \"W bs.\":\"whisper_base_ciempiess_test.trans\",\n",
    "}\n",
    "\n",
    "# ---\n",
    "name2label={v:k for k,v in label2name.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1680958-401f-4d15-a588-9ce29fdb127a",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745e978-69f6-4bd4-b3af-28bf34dba0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to openfiles\n",
    "def open_head(filename):\n",
    "    \"\"\"Opens a reference file in which first token an id\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines=[(gs['id'],gs['trans']) for l in f.readlines() if (gs := re_id_head.match(l.strip()).groupdict())]\n",
    "    return lines\n",
    "\n",
    "def open_tail(filename):\n",
    "    \"\"\"Opens a hypothesis file in which last token an id\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines=[(gs['id'],gs['trans']) for l in f.readlines() if (gs := re_id_tail.match(l.strip()).groupdict())]\n",
    "    return lines\n",
    "\n",
    "def open_transcription_file(filename,format=None):\n",
    "    \"\"\"Opens a trascription file\n",
    "    \n",
    "    param filename: name of file\n",
    "    param format: None, head or tail\"\"\"\n",
    "    if format is None:\n",
    "        with open(filename) as f:\n",
    "            lines=[(None,l) for l in f.readlines()]\n",
    "        return lines\n",
    "    elif format == \"head\":\n",
    "        return open_head(filename)\n",
    "    elif format == \"tail\":\n",
    "        return open_tail(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb82799-c2fb-4c67-8597-851142ea86cd",
   "metadata": {},
   "source": [
    "## Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10bc7b-fa40-4167-8099-8c41f65f05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks number of trasncriptions\n",
    "ref=open_transcription_file(REF_FILE,format=\"head\")\n",
    "print(f\"[green]Reference number of lines:[/] [bold] {len(ref)} [/]\")\n",
    "ids=set( id for id,_ in ref)\n",
    "print(f\"[green]✓ [magenta]Reference [green]has different ids per transcription[/]\")\\\n",
    "        if len(ref) == len(ids) else\\\n",
    "        print(f\"[red]✗ {name} has wrong number of transcriptions[/]\")\n",
    "\n",
    "for idd in labels:\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_transcription_file(file,format=\"tail\")\n",
    "        ids_=set( id[1:-1] for id,_ in hyp)\n",
    "    else:\n",
    "        hyp=open_transcription_file(file,format=\"head\")\n",
    "        ids_=set( id for id,_ in hyp)\n",
    "    print(f\"[green]✓ [magenta]{name} [green]has rigth number of transcriptions[/]\")\\\n",
    "        if len(ref) == len(hyp) else\\\n",
    "        print(f\"[red]✗ {name} has wrong number of transcriptions[/]\")\n",
    "    print(f\"[green]✓ [magenta]{name} [green]has all ids[/]\")\\\n",
    "        if len(ids.difference(ids_))==0 else\\\n",
    "        print(f\"[red]✗ {name} does not have all ids[/]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c26ab9-d6de-4a91-8fde-7648821ecb04",
   "metadata": {},
   "source": [
    "## jiwer evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99d70e-4394-4dae-856d-34c15fc79758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=open_head(REF_FILE)\n",
    "for idd in labels:\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_tail(file)\n",
    "    else:\n",
    "        hyp=open_head(file)\n",
    "    measures = jiwer.compute_measures([trans for _,trans in ref], [trans for _,trans in hyp])\n",
    "    wer = measures['wer']\n",
    "    cer = jiwer.cer([trans for _,trans in ref], [trans for _,trans in hyp])\n",
    "    print(measures.keys())\n",
    "    print(f\"[magenta]{idd:6s} [{name[:-6]}][/]:\")\n",
    "    print(f\"[green]  wer:[/] {wer*100:3.2f}\")\n",
    "    print(f\"[green]  cer:[/] {cer*100:3.2f}\")\n",
    "    print(f\"[green]  hits:[/] {measures['hits']:3d}\")\n",
    "    print(f\"[green]  deletions:[/] {measures['deletions']:3d}\")\n",
    "    print(f\"[green]  insertions:[/] {measures['insertions']:3d}\")\n",
    "    print(f\"[green]  substitutions:[/] {measures['substitutions']:3d}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b77ed-6b0c-45de-aa31-37ffc62a985c",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bfbe1-6e09-4fe4-bf4b-d8db35facfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=open_head(REF_FILE)\n",
    "MIN_COUNT=0\n",
    "OPS={idd:{} for idd in labels}\n",
    "\n",
    "for idd in labels:\n",
    "    ops={\n",
    "        'delete':Counter(),\n",
    "        'insert':Counter(),\n",
    "        'replace':Counter(),\n",
    "        'replace_R':Counter(),\n",
    "        'replace_H':Counter(),\n",
    "        }\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_tail(file)\n",
    "    else:\n",
    "        hyp=open_head(file)\n",
    "    for t1,t2 in zip([trans.split() for _,trans in ref], [trans.split() for _,trans in hyp]):\n",
    "        editops = Levenshtein.opcodes(t1,t2)\n",
    "        for op,ri,rf,hi,hf in editops:\n",
    "            if op==\"delete\":\n",
    "                ops[op].update(t1[ri:rf])\n",
    "            if op==\"insert\":\n",
    "                ops[op].update(t2[hi:hf])\n",
    "            if op==\"replace\":\n",
    "                ops[op].update(f\"{x}->{y}\" for x,y in zip(t1[ri:rf],t2[hi:hf]))\n",
    "                ops['replace_R'][f\"{' '.join(t1[ri:rf])}\"]+=1\n",
    "                ops['replace_H'][f\"{' '.join(t2[hi:hf])}\"]+=1\n",
    "    print(f\"[magenta]{idd:6s} [{name[:-6]}][/]:\")\n",
    "    print(f\"[yellow]Delete[/]  ({sum(ops['delete'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['delete'].most_common(10) if c >= MIN_COUNT]))\n",
    "    print(f\"[yellow]Insert[/]  ({sum(ops['insert'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['insert'].most_common(10) if c >= MIN_COUNT]))\n",
    "    print(f\"[yellow]Replace[/] ({sum(ops['replace'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['replace'].most_common(10) if c >= MIN_COUNT]))\n",
    "    OPS[idd]=ops\n",
    "    #print(f\"[yellow]Replace R[/] ({sum(ops['replace_R'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['replace_R'].most_common() if c >= MIN_COUNT]))\n",
    "    #print(f\"[yellow]Replace H[/] ({sum(ops['replace_H'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['replace_H'].most_common() if c >= MIN_COUNT]))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76bad2c-ef00-46ba-bb6d-0df285ae0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown Control size of figure\n",
    "\n",
    "linestyle_tuple = [\n",
    "     ('loosely dotted',        (0, (1, 10))),\n",
    "     ('densely dotted',        (0, (1, 1))),\n",
    "     #('long dash with offset', (5, (10, 3))),\n",
    "     #('loosely dashed',        (0, (5, 10))),\n",
    "     ('dashed',                (0, (5, 5))),\n",
    "     ('densely dashed',        (0, (5, 1))),\n",
    "\n",
    "     #('loosely dashdotted',    (0, (3, 10, 1, 10))),\n",
    "     #('dashdotted',            (0, (3, 5, 1, 5))),\n",
    "     ('densely dashdotted',    (0, (3, 1, 1, 1))),\n",
    "\n",
    "     #('dashdotdotted',         (0, (3, 5, 1, 5, 1, 5))),\n",
    "     #('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n",
    "     ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))]\n",
    "\n",
    "def plot_error_frequencies(op,x_sizefigure=10,y_sizefigure=4):\n",
    "    plt.figure(figsize=(int(x_sizefigure),int(y_sizefigure)))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(f\"Error frequencies in '{op}' edit operation\")\n",
    "    plt.ylabel(\"Word error occurrences (log base 10)\")\n",
    "    plt.xlabel(\"Word error rank (log base 10)\")\n",
    "\n",
    "    c=0;\n",
    "    labels_=[]\n",
    "    for idd,ops in OPS.items():\n",
    "        if idd in [\"Go.\",\"QN\",\"W tn.\",\"W bs.\", \"W sm.\", \"W med.\"]:\n",
    "            continue\n",
    "        index=range(len(ops[op]))\n",
    "        freq=[f for k,f in ops[op].most_common()]\n",
    "\n",
    "        ax.loglog(\n",
    "            index,\n",
    "            freq,\n",
    "            base=10,\n",
    "            color=sns.color_palette('tab10')[c],\n",
    "            linewidth=1.5+(0.3)*c,\n",
    "            linestyle=linestyle_tuple[c][1],\n",
    "        )\n",
    "        labels_.append(idd)\n",
    "\n",
    "        c+=1\n",
    "        ax.set_xscale(\"log\", base=10); ax.set_yscale(\"log\", base=10)\n",
    "    plt.legend(labels=[f\"{l} ({len(OPS[l][op])}/{sum(OPS[l][op].values())})\" for l in labels_])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffd2e5-f2e1-4a37-b413-aa1ff9c5dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_error_frequencies, op=[\"delete\", \"insert\", \"replace\",\"replace_R\",\"replace_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79598a48-76ce-488e-a8db-708197fd5327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
