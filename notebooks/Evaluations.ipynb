{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf84cbd-d5d2-475b-9d71-bb005ed00243",
   "metadata": {},
   "source": [
    "# Evaluation of speech transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea37a7c-a8ca-44ee-9cb8-564ccf2962b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jiwer\n",
    "import Levenshtein\n",
    "from collections import Counter\n",
    "from rich.jupyter import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c8cdd-4011-4746-a7d5-831159039444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions to match id and transcription\n",
    "re_id_head=re.compile(r\"^(?P<id>[^ ]+) (?P<trans>.*)\") # id at the start\n",
    "re_id_tail=re.compile(r\"(?P<trans>.*) (?P<id>[^ ]+)$\") # id at the final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fd7d9-0c49-4ed2-a050-c4044b3b5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the files and directories\n",
    "\n",
    "# Configure this\n",
    "REF_FILE=\"../data/test/CIEMPIESS_TEST.trans\"\n",
    "HYP_DIR=\"../data/output/exp_november2022\"\n",
    "\n",
    "# ---\n",
    "HYP_FILES={file:os.path.join(HYP_DIR,file) for file in os.listdir(HYP_DIR)}\n",
    "print(f\"[green bold]Files to analyse[/] in dir [{HYP_DIR}]:\\n \",\"\\n  \".join([file for file,_ in HYP_FILES.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf3530-1c15-47bc-a05f-51e8a6c835c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels to filenames (inspect files from previous output)\n",
    "\n",
    "# Configure this\n",
    "labels=[\"Go.\",\"QN\",\"W2V\",\"W tn.\",\"W bs.\", \"W sm.\", \"W med.\", \"W lg.\", \"QN FT\",\"W2V FT\"] # We will follow this order\n",
    "label2name={\n",
    "  \"W med.\":\"whisper_medium_ciempiess_test.trans\",\n",
    "  \"W sm.\":\"whisper_small_ciempiess_test.trans\",\n",
    "  \"W tn.\":\"whisper_tiny_ciempiess_test.trans\",\n",
    "  \"Go.\":\"google_ciempiess_test.trans\",\n",
    "  \"W2V FT\":\"wav2vec_carlos_ciempiess_test.trans\",\n",
    "  \"W lg.\":\"whisper_large_ciempiess_test.trans\",\n",
    "  \"W2V\":\"wav2vec_jonatasgrosman_ciempiess_test.trans\",\n",
    "  \"QN FT\":\"nemo_carlos_ciempiess_test.trans\",\n",
    "  \"QN\":\"nemo_nvidia_ciempiess_test.trans\",\n",
    "  \"W bs.\":\"whisper_base_ciempiess_test.trans\",\n",
    "}\n",
    "\n",
    "# ---\n",
    "name2label={v:k for k,v in label2name.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1680958-401f-4d15-a588-9ce29fdb127a",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745e978-69f6-4bd4-b3af-28bf34dba0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to openfiles\n",
    "def open_head(filename):\n",
    "    \"\"\"Opens a reference file in which first token an id\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines=[(gs['id'],gs['trans']) for l in f.readlines() if (gs := re_id_head.match(l.strip()).groupdict())]\n",
    "    return lines\n",
    "\n",
    "def open_tail(filename):\n",
    "    \"\"\"Opens a hypothesis file in which last token an id\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines=[(gs['id'],gs['trans']) for l in f.readlines() if (gs := re_id_tail.match(l.strip()).groupdict())]\n",
    "    return lines\n",
    "\n",
    "def open_transcription_file(filename,format=None):\n",
    "    \"\"\"Opens a trascription file\n",
    "    \n",
    "    param filename: name of file\n",
    "    param format: None, head or tail\"\"\"\n",
    "    if format is None:\n",
    "        with open(filename) as f:\n",
    "            lines=[(None,l) for l in f.readlines()]\n",
    "        return lines\n",
    "    elif format == \"head\":\n",
    "        return open_head(filename)\n",
    "    elif format == \"tail\":\n",
    "        return open_tail(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb82799-c2fb-4c67-8597-851142ea86cd",
   "metadata": {},
   "source": [
    "## Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10bc7b-fa40-4167-8099-8c41f65f05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks number of trasncriptions\n",
    "ref=open_transcription_file(REF_FILE,format=\"head\")\n",
    "print(f\"[green]Reference number of lines:[/] [bold] {len(ref)} [/]\")\n",
    "ids=set( id for id,_ in ref)\n",
    "print(f\"[green]✓ [magenta]Reference [green]has different ids per transcription[/]\")\\\n",
    "        if len(ref) == len(ids) else\\\n",
    "        print(f\"[red]✗ {name} has wrong number of transcriptions[/]\")\n",
    "\n",
    "for idd in labels:\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_transcription_file(file,format=\"tail\")\n",
    "        ids_=set( id[1:-1] for id,_ in hyp)\n",
    "    else:\n",
    "        hyp=open_transcription_file(file,format=\"head\")\n",
    "        ids_=set( id for id,_ in hyp)\n",
    "    print(f\"[green]✓ [magenta]{name} [green]has rigth number of transcriptions[/]\")\\\n",
    "        if len(ref) == len(hyp) else\\\n",
    "        print(f\"[red]✗ {name} has wrong number of transcriptions[/]\")\n",
    "    print(f\"[green]✓ [magenta]{name} [green]has all ids[/]\")\\\n",
    "        if len(ids.difference(ids_))==0 else\\\n",
    "        print(f\"[red]✗ {name} does not have all ids[/]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c26ab9-d6de-4a91-8fde-7648821ecb04",
   "metadata": {},
   "source": [
    "## jiwer evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99d70e-4394-4dae-856d-34c15fc79758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=open_head(REF_FILE)\n",
    "for idd in labels:\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_tail(file)\n",
    "    else:\n",
    "        hyp=open_head(file)\n",
    "    measures = jiwer.compute_measures([trans for _,trans in ref], [trans for _,trans in hyp])\n",
    "    wer = measures['wer']\n",
    "    cer = jiwer.cer([trans for _,trans in ref], [trans for _,trans in hyp])\n",
    "    print(f\"[magenta]{idd:6s} [{name[:-6]}][/]:\")\n",
    "    print(f\"[green]  wer:[/] {wer*100:3.2f}\")\n",
    "    print(f\"[green]  cer:[/] {cer*100:3.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b77ed-6b0c-45de-aa31-37ffc62a985c",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bfbe1-6e09-4fe4-bf4b-d8db35facfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=open_head(REF_FILE)\n",
    "MIN_COUNT=10\n",
    "\n",
    "for idd in labels:\n",
    "    ops={\n",
    "        'delete':Counter(),\n",
    "        'insert':Counter(),\n",
    "        'replace':Counter(),\n",
    "        'replace_R':Counter(),\n",
    "        'replace_H':Counter(),\n",
    "        }\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_tail(file)\n",
    "    else:\n",
    "        hyp=open_head(file)\n",
    "    for t1,t2 in zip([trans.split() for _,trans in ref], [trans.split() for _,trans in hyp]):\n",
    "        editops = Levenshtein.opcodes(t1,t2)\n",
    "        for op,ri,rf,hi,hf in editops:\n",
    "            if op==\"delete\":\n",
    "                ops[op][f\"{' '.join(t1[ri:rf])}\"]+=1\n",
    "            if op==\"insert\":\n",
    "                ops[op][f\"{' '.join(t2[hi:hf])}\"]+=1\n",
    "            if op==\"replace\":\n",
    "                ops[op][f\"{' '.join(t1[ri:rf])}->{' '.join(t2[hi:hf])}\"]+=1\n",
    "                ops['replace_R'][f\"{' '.join(t1[ri:rf])}\"]+=1\n",
    "                ops['replace_H'][f\"{' '.join(t2[hi:hf])}\"]+=1\n",
    "    print(f\"[magenta]{idd:6s} [{name[:-6]}][/]:\")\n",
    "    print(f\"[yellow]Delete[/]  ({sum(ops['delete'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['delete'].most_common() if c >= MIN_COUNT]))\n",
    "    print(f\"[yellow]Insert[/]  ({sum(ops['insert'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['insert'].most_common() if c >= MIN_COUNT]))\n",
    "    print(f\"[yellow]Replace[/] ({sum(ops['replace'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['replace'].most_common() if c >= MIN_COUNT]))\n",
    "    #print(f\"[yellow]Replace R[/] ({sum(ops['replace_R'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['replace_R'].most_common() if c >= MIN_COUNT]))\n",
    "    #print(f\"[yellow]Replace H[/] ({sum(ops['replace_H'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{c: 3d}[/]\" for k,c in ops['replace_H'].most_common() if c >= MIN_COUNT]))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52764f8c-8632-4748-b18b-e2419156df1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
