{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf84cbd-d5d2-475b-9d71-bb005ed00243",
   "metadata": {},
   "source": [
    "# Evaluation of speech transcriptions\n",
    "\n",
    "This code reproduce the analysis for paper __Anonymized__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea37a7c-a8ca-44ee-9cb8-564ccf2962b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jiwer\n",
    "import Levenshtein\n",
    "from collections import Counter\n",
    "from rich.jupyter import print\n",
    "from rich.console import Console\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "## Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1d99a-63e5-4146-8366-65567aae8d95",
   "metadata": {},
   "source": [
    "# ❶ Prepare _Reference_ transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bafbc-e574-4db4-bac9-a6289c129ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare directory\n",
    "\n",
    "DIR_TEST_FILES=os.path.join('..','data','test')\n",
    "\n",
    "print(f\"About to create directory: [green]{DIR_TEST_FILES}[/]\")\n",
    "\n",
    "try:\n",
    "    os.makedirs('../data/test')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636d9d0-0780-487b-8a7a-d324cecf3e23",
   "metadata": {},
   "source": [
    "## Dowload file with transcriptions\n",
    "\n",
    "Open the following link: https://mega.nz/folder/0shhAaQT#KaoWJ7XOVjDu_2k_JYzyoA/file/FpZgDQqR\n",
    "\n",
    "Download the file: _CIEMPIESS_TEST.trascription_ into the folder: __data/test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143aced4-56a8-4de0-9718-0ec715702ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename file\n",
    "\n",
    "if  os.path.exists(os.path.join(DIR_TEST_FILES,'CIEMPIESS_TEST.transcriptions')):\n",
    "    os.rename(os.path.join(DIR_TEST_FILES,'CIEMPIESS_TEST.transcriptions'), \n",
    "              os.path.join(DIR_TEST_FILES,'CIEMPIESS_TEST.trans'))\n",
    "    print(f\"{os.path.join(DIR_TEST_FILES,'CIEMPIESS_TEST.transcriptions')} -> {os.path.join(DIR_TEST_FILES,'CIEMPIESS_TEST.trans')}\")\n",
    "else:\n",
    "    print(f\"[red]File {os.path.join(DIR_TEST_FILES,'CIEMPIESS_TEST.transcriptions')} not found[/]\")\n",
    "    \n",
    "if not os.path.join(DIR_TEST_FILES,'CIEMPIESS_TEST.trans'):\n",
    "    print(f\"[bold bright_red]✗ Transcription file not found: {os.path.join(DIR_TEST_FILES,'CIEMPIESS_TEST.trans')} it is not possible to continue [/]\")\n",
    "else:\n",
    "    print(f\"[bold bright_green]✓ Reference transcription file in place[/]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f2ae0-7810-4f31-81be-ca8a7e68e54c",
   "metadata": {},
   "source": [
    "# ❷ Checking Hypothesis transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c8cdd-4011-4746-a7d5-831159039444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions to match id and transcription\n",
    "re_id_head=re.compile(r\"^(?P<id>[^ ]+) (?P<trans>.*)\") # id at the start\n",
    "re_id_tail=re.compile(r\"(?P<trans>.*) (?P<id>[^ ]+)$\") # id at the final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fd7d9-0c49-4ed2-a050-c4044b3b5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the files and directories\n",
    "\n",
    "# Configure this\n",
    "REF_FILE=\"../data/test/CIEMPIESS_TEST.trans\"\n",
    "HYP_DIR=\"../data/output/exp_november2022\"\n",
    "\n",
    "# ---\n",
    "HYP_FILES={file:os.path.join(HYP_DIR,file) for file in os.listdir(HYP_DIR)}\n",
    "print(f\"[green bold]Files to analyse[/] in dir [{HYP_DIR}]:\\n \",\"\\n  \".join([file for file,_ in HYP_FILES.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf3530-1c15-47bc-a05f-51e8a6c835c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels to filenames (inspect files from previous output)\n",
    "\n",
    "# Configure this\n",
    "labels=[\"Go.\",\"QN\",\"W2V\",\"W tn.\",\"W bs.\", \"W sm.\", \"W med.\", \"W lg.\", \"QN FT\",\"W2V FT\"] # We will follow this order\n",
    "label2name={\n",
    "  \"W med.\":\"whisper_medium_ciempiess_test.trans\",\n",
    "  \"W sm.\":\"whisper_small_ciempiess_test.trans\",\n",
    "  \"W tn.\":\"whisper_tiny_ciempiess_test.trans\",\n",
    "  \"Go.\":\"google_ciempiess_test.trans\",\n",
    "  \"W2V FT\":\"wav2vec_carlos_ciempiess_test.trans\",\n",
    "  \"W lg.\":\"whisper_large_ciempiess_test.trans\",\n",
    "  \"W2V\":\"wav2vec_jonatasgrosman_ciempiess_test.trans\",\n",
    "  \"QN FT\":\"nemo_carlos_ciempiess_test.trans\",\n",
    "  \"QN\":\"nemo_nvidia_ciempiess_test.trans\",\n",
    "  \"W bs.\":\"whisper_base_ciempiess_test.trans\",\n",
    "}\n",
    "\n",
    "# ---\n",
    "name2label={v:k for k,v in label2name.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1680958-401f-4d15-a588-9ce29fdb127a",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5745e978-69f6-4bd4-b3af-28bf34dba0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to openfiles\n",
    "def open_head(filename):\n",
    "    \"\"\"Opens a reference file in which first token an id\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines=[(gs['id'],gs['trans']) for l in f.readlines() if (gs := re_id_head.match(l.strip()).groupdict())]\n",
    "    return lines\n",
    "\n",
    "def open_tail(filename):\n",
    "    \"\"\"Opens a hypothesis file in which last token an id\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines=[(gs['id'],gs['trans']) for l in f.readlines() if (gs := re_id_tail.match(l.strip()).groupdict())]\n",
    "    return lines\n",
    "\n",
    "def open_transcription_file(filename,format=None):\n",
    "    \"\"\"Opens a trascription file\n",
    "    \n",
    "    param filename: name of file\n",
    "    param format: None, head or tail\"\"\"\n",
    "    if format is None:\n",
    "        with open(filename) as f:\n",
    "            lines=[(None,l) for l in f.readlines()]\n",
    "        return lines\n",
    "    elif format == \"head\":\n",
    "        return open_head(filename)\n",
    "    elif format == \"tail\":\n",
    "        return open_tail(filename)\n",
    "    \n",
    "def normalize_counts(most_common,voca,min_count=3):\n",
    "    if  isinstance(most_common.most_common(1)[0][0],tuple):\n",
    "        vals=[((k1,k2),c,c/min(voca.get(k1,1),voca.get(k2,1))) for (k1,k2),c in most_common.most_common() if c >= min_count]\n",
    "    else:\n",
    "        vals=[(k,c,c/voca.get(k,1)) for k,c in most_common.most_common() if c >= min_count]\n",
    "    vals.sort(key=lambda k: k[2],reverse=True)\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb82799-c2fb-4c67-8597-851142ea86cd",
   "metadata": {},
   "source": [
    "# ❸ Check against reference transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fd10bc7b-fa40-4167-8099-8c41f65f05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks number of trasncriptions\n",
    "ref=open_transcription_file(REF_FILE,format=\"head\")\n",
    "print(f\"[green]Reference number of lines:[/] [bold] {len(ref)} [/]\")\n",
    "ids=set( id for id,_ in ref)\n",
    "print(f\"[green]✓ [magenta]Reference [green]has different ids per transcription[/]\")\\\n",
    "        if len(ref) == len(ids) else\\\n",
    "        print(f\"[red]✗ {name} has wrong number of transcriptions[/]\")\n",
    "\n",
    "VOCA=Counter()\n",
    "for _,l in ref:\n",
    "    VOCA.update(l.split())\n",
    "\n",
    "for idd in labels:\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_transcription_file(file,format=\"tail\")\n",
    "        ids_=set( id[1:-1] for id,_ in hyp)\n",
    "    else:\n",
    "        hyp=open_transcription_file(file,format=\"head\")\n",
    "        ids_=set( id for id,_ in hyp)\n",
    "    print(f\"[green]✓ [magenta]{name} [green]has rigth number of transcriptions[/]\")\\\n",
    "        if len(ref) == len(hyp) else\\\n",
    "        print(f\"[red]✗ {name} has wrong number of transcriptions[/]\")\n",
    "    print(f\"[green]✓ [magenta]{name} [green]has all ids[/]\")\\\n",
    "        if len(ids.difference(ids_))==0 else\\\n",
    "        print(f\"[red]✗ {name} does not have all ids[/]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c26ab9-d6de-4a91-8fde-7648821ecb04",
   "metadata": {},
   "source": [
    "# ❹ evaluation with _jiwer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6f99d70e-4394-4dae-856d-34c15fc79758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copare reference with hypothesis files\n",
    "\n",
    "ref=open_head(REF_FILE)\n",
    "for idd in labels:\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_tail(file)\n",
    "    else:\n",
    "        hyp=open_head(file)\n",
    "    measures = jiwer.compute_measures([trans for _,trans in ref], [trans for _,trans in hyp])\n",
    "    wer = measures['wer']\n",
    "    cer = jiwer.cer([trans for _,trans in ref], [trans for _,trans in hyp])\n",
    "    print(measures.keys())\n",
    "    print(f\"[magenta]{idd:6s} [{name[:-6]}][/]:\")\n",
    "    print(f\"[green]  wer:[/] {wer*100:3.2f}\")\n",
    "    print(f\"[green]  cer:[/] {cer*100:3.2f}\")\n",
    "    print(f\"[green]  hits:[/] {measures['hits']:3d}\")\n",
    "    print(f\"[green]  deletions:[/] {measures['deletions']:3d}\")\n",
    "    print(f\"[green]  insertions:[/] {measures['insertions']:3d}\")\n",
    "    print(f\"[green]  substitutions:[/] {measures['substitutions']:3d}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b77ed-6b0c-45de-aa31-37ffc62a985c",
   "metadata": {},
   "source": [
    "## Errors analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1d8bfbe1-6e09-4fe4-bf4b-d8db35facfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=open_head(REF_FILE)\n",
    "MIN_COUNT=5\n",
    "PRINT_COUNT=30\n",
    "OPS={idd:{} for idd in labels}\n",
    "\n",
    "for idd in labels:\n",
    "    ops={\n",
    "        'delete':Counter(),\n",
    "        'insert':Counter(),\n",
    "        'replace':Counter(),\n",
    "        'replace_R':Counter(),\n",
    "        'replace_H':Counter(),\n",
    "        }\n",
    "    name=label2name[idd]\n",
    "    file=HYP_FILES[name]\n",
    "    if idd in [\"Go.\"]:\n",
    "        hyp=open_tail(file)\n",
    "    else:\n",
    "        hyp=open_head(file)\n",
    "    for t1,t2 in zip([trans.split() for _,trans in hyp], [trans.split() for _,trans in ref]):\n",
    "        editops = Levenshtein.opcodes(t1,t2)\n",
    "        for op,hi,hf,ri,rf in editops:\n",
    "            if op==\"delete\":\n",
    "                ops[op].update(t1[hi:hf])\n",
    "            if op==\"insert\":\n",
    "                ops[op].update(t2[ri:rf])\n",
    "            if op==\"replace\":\n",
    "                ops[op].update((x,y) for x,y in zip(t1[hi:hf],t2[ri:rf]))\n",
    "                ops['replace_H'].update(x for x,y in zip(t1[hi:hf],t2[ri:rf]))\n",
    "                ops['replace_R'].update(y for x,y in zip(t1[hi:hf],t2[ri:rf]))\n",
    "    print(f\"[magenta]{idd:6s} [{name[:-6]}][/]:\")\n",
    "    print(f\"[yellow]Delete[/]  ({sum(ops['delete'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{n:6.4f},{c}[/]\" for k,c,n in normalize_counts(ops['delete'],VOCA,min_count=MIN_COUNT)[:PRINT_COUNT] ]))\n",
    "    print(f\"[yellow]Insert[/]  ({sum(ops['insert'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{n:6.4f},{c}[/]\" for k,c,n in normalize_counts(ops['insert'],VOCA,min_count=MIN_COUNT)[:PRINT_COUNT]]))\n",
    "    print(f\"[yellow]Replace[/] ({sum(ops['replace'].values())}): \",\" \".join([ f\"[white bold]{k[0]}->{k[1]}[/]:[cyan]{n:6.4f},{c}[/]\" for k,c,n in normalize_counts(ops['replace'],VOCA,min_count=MIN_COUNT)[:PRINT_COUNT]]))\n",
    "    OPS[idd]=ops\n",
    "    print(f\"[yellow]Replace_H[/]  ({sum(ops['replace_H'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{n:6.4f},{c}[/]\" for k,c,n in normalize_counts(ops['replace_R'],VOCA,min_count=MIN_COUNT)[:PRINT_COUNT] ]))\n",
    "    print(f\"[yellow]Replace_I[/]  ({sum(ops['replace_R'].values())}): \",\" \".join([ f\"[white bold]{k}[/]:[cyan]{n:6.4f},{c}[/]\" for k,c,n in normalize_counts(ops['replace_H'],VOCA,min_count=MIN_COUNT)[:PRINT_COUNT]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eeebcb-88b1-4553-ac58-9bd84920dfb3",
   "metadata": {},
   "source": [
    "## Plot requency of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c76bad2c-ef00-46ba-bb6d-0df285ae0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown Control size of figure\n",
    "linestyle_tuple = [\n",
    "     ('loosely dotted',        (0, (1, 3))),\n",
    "     ('densely dotted',        (0, (1, 1))),\n",
    "     ('long dash with offset', (5, (10, 3))),\n",
    "     ('loosely dashed',        (0, (5, 10))),\n",
    "     ('dashed',                (0, (5, 5))),\n",
    "     ('densely dashed',        (0, (5, 1))),\n",
    "\n",
    "     ('loosely dashdotted',    (0, (3, 10, 1, 10))),\n",
    "     ('dashdotted',            (0, (3, 5, 1, 5))),\n",
    "     ('densely dashdotted',    (0, (3, 1, 1, 1))),\n",
    "\n",
    "     #('dashdotdotted',         (0, (3, 5, 1, 5, 1, 5))),\n",
    "     #('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n",
    "     ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))]\n",
    "\n",
    "def plot_error_frequencies(op,x_sizefigure=10,y_sizefigure=4):\n",
    "    plt.figure(figsize=(int(x_sizefigure),int(y_sizefigure)))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(f\"Error frequencies in '{op}' edit operation\")\n",
    "    plt.ylabel(\"Word error occurrences (log base 10)\")\n",
    "    plt.xlabel(\"Word error rank (log base 10)\")\n",
    "\n",
    "    c=0\n",
    "    col=0\n",
    "    labels_=[]\n",
    "    for idd,ops in OPS.items():\n",
    "        \n",
    "        if idd in []:#\"Go.\",\"QN\",\"W tn.\",\"W bs.\", \"W sm.\", \"W med.\"]:\n",
    "            col+=1\n",
    "            continue\n",
    "        index=range(len(ops[op]))\n",
    "        freq=[f for k,f in ops[op].most_common()]\n",
    "\n",
    "        ax.loglog(\n",
    "            index,\n",
    "            freq,\n",
    "            base=10,\n",
    "            color=sns.color_palette('colorblind')[col],\n",
    "            linewidth=1.5+(0.3)*c,\n",
    "            linestyle=linestyle_tuple[c][1],\n",
    "        )\n",
    "        labels_.append(idd)\n",
    "\n",
    "        c+=1\n",
    "        col+=1\n",
    "        ax.set_xscale(\"log\", base=10); ax.set_yscale(\"log\", base=10)\n",
    "    plt.legend(labels=[f\"{l} ({len(OPS[l][op])}/{sum(OPS[l][op].values())})\" for l in labels_])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6bffd2e5-f2e1-4a37-b413-aa1ff9c5dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_error_frequencies, op=[\"delete\", \"insert\", \"replace\",\"replace_R\",\"replace_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fd3fb6ee-bd86-48a5-8e6f-4ba6d567b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalized_frequencies(op,x_sizefigure=10,y_sizefigure=4):\n",
    "    plt.figure(figsize=(int(x_sizefigure),int(y_sizefigure)))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(f\"Error normalize frequencies in '{op}' edit operation\")\n",
    "    plt.ylabel(\"Word normalized error (log base 10)\")\n",
    "    plt.xlabel(\"Word error rank (log base 10)\")\n",
    "\n",
    "    c=0\n",
    "    col=0\n",
    "    labels_=[]\n",
    "    for idd,ops in OPS.items():\n",
    "        \n",
    "        if idd in []:#\"Go.\",\"QN\",\"W tn.\",\"W bs.\", \"W sm.\", \"W med.\"]:\n",
    "            col+=1\n",
    "            continue\n",
    "       \n",
    "        freq=[n for k,c,n in normalize_counts(ops[op],VOCA,min_count=0)]\n",
    "        index=range(len(freq))\n",
    "        ax.loglog(\n",
    "            index,\n",
    "            freq,\n",
    "            base=10,\n",
    "            color=sns.color_palette('colorblind')[col],\n",
    "            linewidth=1.5+(0.3)*c,\n",
    "            linestyle=linestyle_tuple[c][1],\n",
    "        )\n",
    "        labels_.append(idd)\n",
    "\n",
    "        c+=1\n",
    "        col+=1\n",
    "        ax.set_xscale(\"log\", base=10) \n",
    "        ax.set_yscale(\"log\", base=10)\n",
    "    plt.legend(labels=[f\"{l} ({len(normalize_counts(OPS[l][op],VOCA,min_count=0))}/{sum(OPS[l][op].values())})\" for l in labels_])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aaf558c1-12e6-48a7-ac49-d067633a0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_normalized_frequencies, op=[\"delete\", \"insert\", \"replace\",\"replace_R\",\"replace_H\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234e033-04c1-4c28-b98c-20c59c6047e1",
   "metadata": {},
   "source": [
    "## Replace analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9e80a095-1a4a-4083-994c-7c6348b1d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,10,figsize=(15,2))\n",
    "fig.suptitle(\"Number of edits in replacement operations\")\n",
    "#fig.supxlabel(\"Number of edits\")\n",
    "labels_=[]\n",
    "c=0\n",
    "for idd,ops in OPS.items():\n",
    "    if idd in []:\n",
    "            continue\n",
    "    hist=[]\n",
    "    for (r,h),f in ops['replace'].most_common():\n",
    "        editops = Levenshtein.editops(r,h)\n",
    "        hist.append(len(editops),)\n",
    "    \n",
    "    labels_.append(idd)\n",
    "    \n",
    "    ax[c].hist(hist,color=sns.color_palette('colorblind')[c])\n",
    "    ax[c].set_xlim(right=20,left=1)\n",
    "    ax[c].set_ylim(top=8000)\n",
    "    ax[c].set_xlabel(idd)\n",
    "    ax[c].text(10,7000,f\"{sum(hist):,d}\")\n",
    "\n",
    "    if c!=0:\n",
    "        ax[c].set_yticks([])\n",
    "    \n",
    "    c+=1\n",
    "\n",
    "#fig.legend(labels=labels_,loc=7)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae797923-c619-45cc-b2a9-e0f8b218b776",
   "metadata": {},
   "source": [
    "## lenght of words in errors analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a2a596ea-b18d-4cf4-b97d-859617cf0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms_lenghts(op,top=7000,right=20,x_sizefigure=15,y_sizefigure=2):\n",
    "    fig, ax = plt.subplots(1,10,figsize=(x_sizefigure,y_sizefigure))\n",
    "    fig.suptitle(f\"Lenght of words in '{op}' operation\")\n",
    "    #fig.supxlabel(\"Number of edits\")\n",
    "    labels_=[]\n",
    "    c=0\n",
    "    max_=0\n",
    "    max_length=0\n",
    "    for idd,ops in OPS.items():\n",
    "        hist=[]\n",
    "        for w,f in ops[op].most_common():\n",
    "            hist.append(len(w))\n",
    "\n",
    "        counts, bins = np.histogram(hist,bins=max(hist))\n",
    "        max_=max(max(counts),max_)\n",
    "        max_length=max(max(hist),max_length)\n",
    "      \n",
    "    \n",
    "    for idd,ops in OPS.items():\n",
    "        if idd in []:\n",
    "                continue\n",
    "        hist=[]\n",
    "        for w,f in ops[op].most_common():\n",
    "            hist.append(len(w))\n",
    "\n",
    "        labels_.append(idd)\n",
    "\n",
    "        counts, edges, bars = ax[c].hist(hist,color=sns.color_palette('colorblind')[c],bins=max_length)\n",
    "        ax[c].set_xlim(left=1,right=max_length)\n",
    "        ax[c].set_ylim(top=int(max_*1.1))\n",
    "        ax[c].set_xlabel(idd)\n",
    "        \n",
    "        #ax[c].bar_label(bars)\n",
    "        ax[c].text(11,max_,f\"Md: {int(np.median(hist)):d}\")\n",
    "\n",
    "        if c!=0:\n",
    "            ax[c].set_yticks([])\n",
    "\n",
    "        c+=1\n",
    "\n",
    "    #fig.legend(labels=labels_,loc=7)\n",
    "    plt.show()       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "92485a7b-25e5-4e82-99ec-2d56cc80c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_histograms_lenghts, op=[\"delete\", \"insert\",\"replace_R\",\"replace_H\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
